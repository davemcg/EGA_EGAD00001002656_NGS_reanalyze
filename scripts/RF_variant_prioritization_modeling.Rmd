---
title: "RF Model"
output: html_notebook
---




# Load data from stats.Rmd
```{r}
# load('/Volumes/Arges_NFS/PROJECTS/mcgaughey/EGA_EGAD00001002656_NGS_reanalyze/clean_data/gemini_out_variants_het_and_hom.Rdata')
load('~/Desktop/gemini_out_variants_het_and_hom.Rdata')
```

# Set up data for modeling
```{r}
library(tidyverse)

all_processed <- all %>% 
  separate(gene_eyediseaseclass, c('RDGene','DiseaseClass'), sep='_') %>%  #split off RD disease type
  select(-RDGene) %>% 
  mutate(impact_severity = case_when(impact_severity == 'HIGH' ~ 3, # convert to integer 
                                      impact_severity == 'MED' ~ 2, 
                                      TRUE ~ 1),
         Status = case_when(Status=='Pathogenic' ~ 'Pathogenic',
                            TRUE ~ 'NotPathogenic')) %>% 
  mutate(Status = factor(Status, levels=c('Pathogenic','NotPathogenic'))) %>% 
  mutate_at(vars(matches('ac_|an_|^n_')), funs(as.integer(.))) %>% # convert columns with ac_|whatever to integer (ac is allele count)
  mutate_at(vars(matches('af_|dann|revel|mpc|gerp|polyphen_score|sift_score|fitcons_float|gerp_elements|^adj|_z$|^pli$|^pnull$|precessive|^phylop')), funs(as.numeric(.))) %>%  # af is allele frequency
select(variant_id, Status, Complicated_Status, is_exonic, is_coding, is_lof, is_splicing, impact_severity, polyphen_score, sift_score,  DiseaseClass, aaf_1kg_afr_float:an_exac_sas, fitcons_float, gerp_elements, lof_z:precessive, phylop_100way, grantham, cadd_phred)

all_processed[is.na(all_processed)] <- -1

all_PATH <- all_processed %>% 
  filter(Status=='Pathogenic') %>% 
  unique()
all_NOT_PATH <- all_processed %>% 
  filter(Status=='NotPathogenic') %>% 
  unique()

all_set <- all_processed

all_PATH <- all_set %>% filter(Status=='Pathogenic')
# cut down pathogenic to 5x of path
set.seed(115470)
all_NOT_PATH__CUT <- all_set %>% filter(Status=='NotPathogenic', max_aaf_all < 0.02) %>% sample_n(nrow(all_PATH) * 5)

ML_set <- rbind(all_PATH, all_NOT_PATH__CUT)


```

## One hot encoding (Dummy variables)
Turn categorical factors into variables

Many ML algorithms can't handle factor

You can feed this into the `Train and Test sets` section below if you are using something like a GLM or NN. 

```{r, eval = F}
library(dummies)
temp <- ML_set %>% dplyr::select(-Status, -Complicated_Status)
temp <- dummy.data.frame(temp, sep='_')
ML_set_dummy <- temp %>% mutate(Status = ML_set$Status, Complicated_Status = ML_set$Complicated_Status)
# recreate for full data
temp <- all_set %>% dplyr::select(-Status, -Complicated_Status)
temp <- dummy.data.frame(temp, sep='_')
all_dummy <- temp %>% mutate(Status = all_set$Status, Complicated_Status = all_set$Complicated_Status)
```

# Identify highly correlated metrics
```{r}
correlated <- cor(all_dummy %>% select(-Status, -Complicated_Status))
indices <- findCorrelation(correlated)
colnames(all_dummy %>% select(-Status, -Complicated_Status))[indices]
```

## Train and Validate and Test sets
Split in training / validating / testing

```{r}
set.seed(115470)
train_set <- ML_set_dummy %>% 
  group_by(Status, Complicated_Status) %>% 
 # filter(!Complicated_Status=='Comp_Het') %>% # remove comp hets for now
  sample_frac(0.33) %>% ungroup()
# remove no variance columns
#var_columns <- colnames(train_set)[apply(train_set, MARGIN = 2, function(x) var(x) > 0)]
#var_columns <- var_columns[!is.na(var_columns)]
#train_set <- train_set[,c(var_columns, 'Status', 'Complicated_Status')]

validate_set <- ML_set_dummy %>% 
  filter(!variant_id %in% train_set$variant_id) %>% 
  group_by(Status, Complicated_Status) %>% 
  sample_frac(0.5) %>% ungroup()

test_set <- ML_set_dummy %>% 
  filter(!variant_id %in% c(train_set$variant_id, validate_set$variant_id))
# remove no variance columns
#var_columns <- colnames(test_set)[apply(test_set, MARGIN = 2, function(x) var(x) > 0)]
#var_columns <- var_columns[!is.na(var_columns)]
#test_set <- test_set[,c(var_columns, 'Status', 'Complicated_Status')]
```

## Recipe
skip for now
```{r, eval=FALSE}
library(caret)
train_setR <- train_set %>% dplyr::select(-Complicated_Status, -variant_id)
rec_obj <- recipe(Status ~ ., data = train_setR)
```



## Modeling

```{r}
library(caret)
library(mlbench)
library(parallel)
library(doParallel)
library(MLmetrics)
#library(plotROC)

# CV on rf seems to overfit
fitControl_RF <- trainControl(
  classProbs=T,
  savePredictions = T,
  allowParallel = T,
  summaryFunction = twoClassSummary)

fitControl <- trainControl(## 5-fold CV
  method = "cv",
  number = 5,
  classProbs=T,
  savePredictions = T,
  allowParallel = T,
  summaryFunction = twoClassSummary)
cluster <- makeCluster(detectCores() - 1) # leave some cores for me!
registerDoParallel(cluster)


rfFit <- caret::train(Status ~ ., data=train_set %>% select(-Complicated_Status), 
                      preProcess = c("scale", "center"),
                      method = "rf", metric='Sens',
                      trControl = fitControl_RF)

bglmFit <- caret::train(x=train_set %>% 
                        dplyr::select_(.dots=columns) %>% 
                        data.frame(), 
                      y = train_set$Status, 
                      #preProcess = c("scale", "center"),
                      method = "bayesglm", metric='Sens',
                      trControl = fitControl)
fdaFit <- caret::train(x=train_set %>% 
                        dplyr::select_(.dots=columns) %>% 
                        data.frame(), 
                      y = train_set$Status, 
                      #preProcess = c("scale", "center"),
                      method = "fda",  metric='Sens',
                      trControl = fitControl)
xgbTreeFit <-caret::train(x=train_set %>% 
                        dplyr::select_(.dots=columns) %>% 
                        data.frame(), 
                      y = train_set$Status, 
                     # preProcess = c("scale", "center"),
                      method = "xgbTree",  metric='Sens',
                      trControl = fitControl)
c5.0TreeFit <- caret::train(x=train_set %>% 
                        dplyr::select_(.dots=columns) %>% 
                        data.frame(), 
                      y = train_set$Status, 
                      #preProcess = c("scale", "center"),
                      method = "C5.0Tree", metric='Sens',
                      trControl = fitControl)
stepLDAFit <- caret::train(x=train_set %>% 
                        dplyr::select_(.dots=columns) %>% 
                        data.frame(), 
                      y = train_set$Status, 
                      #preProcess = c("scale", "center"),
                      method = "stepLDA",  metric='Sens',
                      trControl = fitControl)
# cadd only
caddFit <- caret::train(x=train_set %>% 
                        dplyr::select(cadd_phred) %>% 
                        data.frame(), 
                      y = train_set$Status, 
                      #preProcess = c("scale", "center"),
                      method = "glm", 
                      trControl = fitControl)

#stopCluster(cluster)
#registerDoSEQ() # forces R down to single thread - can't do parallel run after this?

my_models <- list(rfFit,bglmFit,xgbTreeFit,c5.0TreeFit,stepLDAFit,caddFit)
names(my_models) <- c('rfFit','bglmFit','xgbTreeFit','c5.0TreeFit','stepLDAFit','caddFit')
```

# ConfusionMatrix your model(s)
```{r}
# fuller_data is all variants, minus the variants in the test_set
fuller_data = all_dummy %>% filter(!variant_id %in% test_set$variant_id)

cm_maker <- function(model, data, cutoff=0.5) {
  new_predictions <- predict(model, data, type='prob') %>%
    mutate(Answers = data$Status, Prediction = case_when(Pathogenic > cutoff ~ 'Pathogenic', TRUE ~ 'NotPathogenic'))
  confusionMatrix(data = new_predictions$Prediction, reference = new_predictions$Answers, mode='prec_recall')
}
#example
cm_maker(bglmFit, fuller_data, cutoff=0.5)
cm_maker(rfFit, fuller_data, cutoff=0.5)
```

# AUC ROC
```{r}
library(PRROC)

# precision recall AUC
aucroc_maker <- function(model, data, cutoff=0.5) {
  new_predictions <- predict(model, data, type = 'prob') %>%
    mutate(Answers = data$Status, Prediction = case_when(Pathogenic > cutoff ~ 'Pathogenic', TRUE ~ 'NotPathogenic'))
  pr.curve(scores.class0 = new_predictions %>% filter(Answers=='Pathogenic') %>% pull(Pathogenic),
           scores.class1 = new_predictions %>% filter(Answers=='NotPathogenic') %>% pull(Pathogenic),
           curve = T)
}

# ROC AUC
roc_maker <- function(model, data, cutoff=0.5) {
  new_predictions <- predict(model, data, type = 'prob') %>%
    mutate(Answers = data$Status, Prediction = case_when(Pathogenic > cutoff ~ 'Pathogenic', TRUE ~ 'NotPathogenic'))
  roc.curve(scores.class0 = new_predictions %>% filter(Answers=='Pathogenic') %>% pull(Pathogenic),
           scores.class1 = new_predictions %>% filter(Answers=='NotPathogenic') %>% pull(Pathogenic),
           curve = T)
}

aucroc_data <- data.frame()
for (i in names(my_models)){
  print(my_models[[i]]$method)
  out <- aucroc_maker(my_models[[i]], all_dummy)
  out <- out$curve[,1:2] %>% data.frame()
  colnames(out) <- c('Recall','Precision')
  out$model <- i
  aucroc_data <- rbind(aucroc_data, out)
}

pr <- aucroc_data %>% ggplot(aes(x=Recall, y=Precision, colour=model)) + geom_line() + theme_minimal() + ggsci::scale_color_aaas() + ggtitle('prROC')


roc_data <- data.frame()
for (i in names(my_models)){
  print(my_models[[i]]$method)
  out <- roc_maker(my_models[[i]], all_dummy)
  out <- out$curve[,1:2] %>% data.frame()
  colnames(out) <- c('FPR','Sensitivity')
  out$model <- i
  roc_data <- rbind(roc_data, out)
}

roc <- roc_data %>% ggplot(aes(x=FPR, y=Sensitivity, colour=model)) + geom_line() + theme_minimal() + ggsci::scale_color_aaas() + ggtitle('aucROC')
library(cowplot)
cowplot::plot_grid(roc, pr)


```
